<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link rel=apple-touch-icon sizes=180x180 href=/favicon/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon/favicon-16x16.png><link rel=manifest href=/favicon/site.webmanifest><link rel=stylesheet type=text/css href=/style.css><title>Inria/Irisa DiverSE Team</title><link href="https://fonts.googleapis.com/css?family=Voces&display=swap" rel=stylesheet></head><body><nav id=main-menu class="shadow-sm navbar navbar-light navbar-expand-md sticky-top bg-light"><a class=navbar-brand href=/><img id=team-logo src=/images/logo-borders.svg width=80 height=80 alt="DiverSE Team"></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbar-items aria-controls=navbar-items aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbar-items><ul class=navbar-nav><li class=nav-item><a class=nav-link href=/topics/><span>Objectives</span></a></li><li class=nav-item><a class=nav-link href=/community/><span>Community</span></a></li><li class=nav-item><a class=nav-link href=/team/><span>Team</span></a></li><li class=nav-item><a class=nav-link href=/projects/><span>Projects</span></a></li><li class=nav-item><a class=nav-link href=/talks/><span>Talks</span></a></li><li class=nav-item><a class=nav-link href=/publications/><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/posts/><span>Posts</span></a></li><li class=nav-item><a class=nav-link href=/software/><span>Software</span></a></li><li class=nav-item><a class=nav-link href=/positions/><span>Join Us!</span></a></li></ul></div></nav><main id=main-content class=bg-light><div class="container py-5 overlay"><h1>Generative AI (LLMs) for Detecting Abnormal Behavior Through Execution Trace Analysis</h1><div id=page-content><div class=information><p class=info-row><span class=label>Position</span><span class=data>
<span class="text-light badge badge-primary">INTERNSHIP (POSSIBLE FOLLOW UP WITH A PHD)</span></span></p><p class=info-row><span class=label>Expected start date</span><span class=data>as soon as possible</span></p><p class=info-row><span class=label>Estimated duration</span><span class=data>from 3 to 6 months</span></p><p class=info-row><span class=label>Education level</span><span class=data></span></p><p class=info-row><span class=label>Contact</span><span class=data>Mathieu Acher and Olivier Zendra</span><a href=mailto:>mathieu.acher@irisa.fr</a></p></div><h2 id=context-and-approach>Context and Approach</h2><p>This project aims to study the contributions of Generative Artificial Intelligence (AI) and Large Language Models (LLMs) to certain aspects of defensive computer security.
This internship provides an <em>opportunity to initiate research work that will continue in a thesis</em>, in collaboration with DiverSE Inria and the Exploration and Research Laboratory in Detection (LED) at ANSSI.</p><h3 id=ambition>Ambition</h3><p>The objective is to create a monitoring program capable of automatically detecting and characterizing when a computer system deviates from its nominal behavior (including in its interactions with the outside). The supervisor can then raise alerts. The result of the analysis is an actionable report for experts.</p><h3 id=approach-and-methodology>Approach and Methodology</h3><p>In this context, LLMs show promise for analyzing execution traces (by classifying, summarizing, or extracting important information from one or more traces). LLMs have recently been at the forefront with initiatives and tools such as BERT, BLOOM, GPT-3, GPT-4, PaLM, Alphacode, Code-Parrot, Codex, ChatGPT, and CoPilot. The ability of LLMs to process or synthesize technical artifacts (code, semi-structured documents, or traces) encourages us to explore their use in a cybersecurity context [Liu et al., 2021, Steenhoek et al., 2022, Zhou et al., 2022]. It is then a matter of studying LLMs in the context of detecting abnormal behaviors of computer programs and systems [Vaccaro and Liepins, 1989, Oliner et al., 2011, Li et al., 2017, Sultana et al., 2019, Khraisat et al., 2019, Thakkar and Lohiya, 2023].</p><p>To achieve this, execution traces (e.g., logs) of various types (system calls [da Costa et al., 2017, Nissim et al., 2018], memory [Panker and Nissim, 2021], network exchanges/packets [Sikos, 2020], etc.) will be collected. Execution traces can be seen as text obeying certain rules: they are semi-structured data. Large Language Models have demonstrated their ability to process this type of data in an agnostic and generic manner, i.e., without the need for syntactic or grammatical analysis. Due to their versatility, LLMs should have excellent capability to classify anomalous behaviors (i.e., executions) of programs and systems, thus enabling the detection of errors, bugs, malicious software, or cyber-attacks.</p><p>The implemented system should take into account existing tools, catalogs, and vulnerability databases to link detections, as much as possible, to these vulnerabilities (e.g., CVEs). Embedding techniques and information retrieval methods need to be developed to make the interaction between LLMs, traces, and data sources effective [Liu et al., 2021, Andrus et al., 2022]. Our vision is to synthesize reports that manage to match traces with vulnerability information; these reports can be utilized by experts to make defensive decisions;</p><h3 id=project-architecture>Project Architecture</h3><p>Figure 1 provides a general overview of the project. Given a cyber system (black box), it is possible to observe it through traces (gray boxes). From a defensive standpoint, these traces can be analyzed to quantify and qualify the cyber system in terms of vulnerabilities or ongoing attacks.
<img src=/positions/LLMsecu.png alt=LLMsecu.png></p><h2 id=internship-work>Internship Work</h2><p>The work to be carried out is structured into three axes:</p><ul><li>Study the bibliography to gain a good understanding of the relevant domains and existing tools. The references cited in this document are a starting point, but the state of the art evolves rapidly, whether it’s on the side of LLMs, software engineering, or security.</li><li>Based on the bibliographic work and in collaboration with ANSSI, design a playground with cyber systems, traces, etc., to be able to experiment with LLMs. Open data or realistic scenarios can be used, and a test bench will be established with the ambition to eventually have reference results for detecting abnormal behaviors from execution traces.</li><li>Implement an experimental prototype of an LLM detecting abnormal behaviors by analyzing traces of a given type. This prototype will be developed by the intern based on the articles and by reusing libraries or available tools as open-source software. Experimental results will be reported, analyzed, and discussed.</li></ul><p>The aim of the internship is to <em>familiarize oneself with the subject and obtain initial results that will then be further developed as part of a 3-year thesis, still in partnership between DiverSE Inria and ANSSI.</em></p><h2 id=supervision-and-contacts>Supervision and Contacts</h2><p>The internship will take place within the DiverSE team at Inria/IRISA Rennes, in collaboration with LED at ANSSI. The DiverSE team has internationally recognized expertise in software engineering, software variability, and automatic techniques for software.
DiverSE has a strong activity in cybersecurity through past or ongoing collaborations, for example recently with Software Heritage (SWH-Sec). DiverSE is co-responsible for an Inria challenge on LLMs and software engineering.</p><p>The National Cybersecurity Agency of France (ANSSI) is the national authority in cybersecurity. Its mission is to understand, prevent, and respond to cyber risk. LED is responsible for the domain of detection and analysis of cyber attacks against information systems, including intrusion detection, analysis of compromised systems or malicious software.</p><h2 id=supervisors>Supervisors:</h2><ul><li>Mathieu ACHER, Professor at INSA Rennes (<a href=mailto:mathieu.acher@inria.fr>mathieu.acher@inria.fr</a>), DiverSE.</li><li>Olivier ZENDRA, Inria Research Scientist (<a href=mailto:olivier.zendra@inria.fr>olivier.zendra@inria.fr</a>), DiverSE.</li><li>Romain BRAULT, Data Science Expert at ANSSI (<a href=mailto:romain.brault@ssi.gouv.fr>romain.brault@ssi.gouv.fr</a>), LED.</li></ul><p><strong>The aim of the internship is to prepare the candidate for research work that will continue with a three-year thesis, carried out in collaboration between DiverSE Inria and ANSSI.</strong></p><h2 id=references>References</h2><p>[Andrus et al., 2022] Andrus, B. R., Nasiri, Y., Cui, S., Cullen, B., and Fulda, N. (2022). Enhanced story comprehension for large language models through dynamic document-based knowledge graphs. In Proceedings of the AAAI Conference on Artificial Intelligence, pages 10436–10444.</p><p>[da Costa et al., 2017] da Costa, V. G. T., Barbon, S., Miani, R. S., Rodrigues, J. J. P. C., and Zarpelão, B. B. (2017). Detecting mobile botnets through machine learning and system calls analysis. In 2017 IEEE International Conference on Communications (ICC), pages 1–6.</p><p>[Khraisat et al., 2019] Khraisat, A., Gondal, I., Vamplew, P., and Kamruzzaman, J. (2019). Survey of intrusion detection systems: techniques, datasets and challenges. Cybersecur, 2(20).</p><p>[Li et al., 2017] Li, T., Jiang, Y., Zeng, C., Xia, B., Liu, Z., Zhou, W., Zhu, X., Wang, W., Zhang, L., Wu, J., Xue, L., and Bao, D. (2017). FLAP: an end-to-end event log analysis platform for system management. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Halifax, NS, Canada, August 13 - 17, 2017, pages 1547–1556. ACM.</p><p>[Liu et al., 2021] Liu, J., Shen, D., Zhang, Y., Dolan, B., Carin, L., and Chen, W. (2021). What makes good in-context examples for gpt-3? arXiv preprint arXiv:2101.06804.</p><p>[Nissim et al., 2018] Nissim, N., Lapidot, Y., Cohen, A., and Elovici, Y. (2018). Trusted system-calls analysis methodology aimed at detection of compromised virtual machines using sequential mining. Knowledge-Based Systems, 153:147–175.</p><p>[Oliner et al., 2011] Oliner, A. J., Ganapathi, A., and Xu, W. (2011). Advances and challenges in log analysis. Queue, 9:30 – 40.</p><p>[Panker and Nissim, 2021] Panker, T. and Nissim, N. (2021). Leveraging malicious behavior traces from volatile memory using machine learning methods for trusted unknown malware detection in linux cloud environments. Knowledge-Based Systems, 226:107095.</p><p>[Sikos, 2020] Sikos, L. F. (2020). Packet analysis for network forensics: A comprehensive survey. Forensic Science International: Digital Investigation,, 32:200892.</p><p>[Steenhoek et al., 2022] Steenhoek, B., Rahman, M. M., Jiles, R., and Le, W. (2022). An empirical study of deep learning models for vulnerability detection. arXiv preprint arXiv:2212.08109.</p><p>[Sultana et al., 2019] Sultana, N., Rao, A., Jin, Z., Pashakhanloo, P., Zhu, H., Yegneswaran, V., and Loo, B. T. (2019). Trace-based behaviour analysis of network servers. In Lutfiyya, H., Diao, Y., Zincir-Heywood, A. N., Badonnel, R., and Madeira, E. R. M., editors, 15th International Conference on Network and Service Management, CNSM 2019, Halifax, NS, Canada, October 21-25, 2019, pages 1–5. IEEE.</p><p>[Thakkar and Lohiya, 2023] Thakkar, A. and Lohiya, R. (2023). A review on challenges and future research directions for machine learning-based intrusion detection system. Arch Computat Methods Eng.</p><p>[Vaccaro and Liepins, 1989] Vaccaro, H. and Liepins, G. (1989). Detection of anomalous computer session activity. In Proceedings. 1989 IEEE Symposium on Security and Privacy, pages 280–289.</p><p>[Zhou et al., 2022] Zhou, Z., Bo, L., Wu, X., Sun, X., Zhang, T., Li, B., Zhang, J., and Cao, S. (2022). Spvf: security property assisted vulnerability fixing via attention-based models. Empirical Software Engineering, 27(7):171.</p><embed src=/pdf/ANSSI_Inria_LLM_Master2024_FR_EN.pdf type=application/pdf width=100% height=600px></div></div></main><footer class="py-5 bg-dark text-light"><div class=container-fluid><div class=container><div class=row><div class="col col-sm-8"><h4>DiverSE</h4><ul id=contact-information><li><i class="fab fa-twitter"></i><a class=text-light href=https://www.twitter.com/@DiverSE_inria>@DiverSE_inria</a></li><li><i class="fab fa-youtube"></i><a class=text-light href=https://www.youtube.com/channel/UCIJQNB3HXuq3_Tl6u_tUeBA>YouTube Channel</a></li><li><i class="fab fa-github"></i><a class=text-light href=https://github.com/diverse-project>diverse-project</a></li><li><i class="fab fa-researchgate"></i><a class=text-light href=https://www.researchgate.com/lab/Olivier-Barais-Lab>Research Gate</a></li><li><i class="fas fa-at"></i><a class=text-light href=mailto:barais@irisa.fr>barais@irisa.fr</a></li><li><i class="fas fa-phone"></i><a class=text-light href=tel:+33%20%280%296.67.60.59.35>+33 (0)6.67.60.59.35</a></li><li><i class="fas fa-map-marker-alt"></i><span class=text-light>Campus de Beaulieu, 263 avenue du Général Leclerc, 35 042 RENNES cedex, France</a></li></ul></div><div class="col-sm-4 row"><ul class="navbar-nav col"><il class=nav-item><a class="text-light nav-link" href=/topics/>Objectives</a></il>
<il class=nav-item><a class="text-light nav-link" href=/community/>Community</a></il>
<il class=nav-item><a class="text-light nav-link" href=/team/>Team</a></il>
<il class=nav-item><a class="text-light nav-link" href=/projects/>Projects</a></il></ul><ul class="navbar-nav col"><il class=nav-item><a class="text-light nav-link" href=/talks/>Talks</a></il>
<il class=nav-item><a class="text-light nav-link" href=/publications/>Publications</a></il>
<il class=nav-item><a class="text-light nav-link" href=/posts/>Posts</a></il>
<il class=nav-item><a class="text-light nav-link" href=/software/>Software</a></il>
<il class=nav-item><a class="text-light nav-link" href=/positions/>Join Us!</a></il></ul></div></div></div></div></footer><script src=https://code.jquery.com/jquery-3.2.1.slim.min.js integrity=sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js integrity=sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q crossorigin=anonymous></script><script src=https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js integrity=sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl crossorigin=anonymous></script></body></html>